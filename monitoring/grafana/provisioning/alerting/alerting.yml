apiVersion: 1

# Grafana Alerting Provisioning
# This file configures alerting contact points, notification policies, and alert rules

# Contact Points - Define where alerts should be sent
contactPoints:
  - orgId: 1
    name: 'default-email'
    receivers:
      - uid: 'email-default'
        type: 'email'
        settings:
          addresses: '${ALERT_EMAIL:-admin@example.com}'
          singleEmail: false
          # Additional email settings can be configured here

# Notification Policies - Define routing rules for alerts
policies:
  - orgId: 1
    receiver: 'default-email'
    group_by: ['alertname', 'cluster', 'service']
    group_wait: '10s'
    group_interval: '10s'
    repeat_interval: '12h'
    routes:
      # Critical alerts - immediate notification
      - matchers:
          - 'severity = critical'
        receiver: 'default-email'
        group_wait: '0s'
        repeat_interval: '1h'
      # Warning alerts - batched notifications
      - matchers:
          - 'severity = warning'
        receiver: 'default-email'
        group_wait: '30s'
        repeat_interval: '6h'

# Alert Rules - Define conditions that trigger alerts
groups:
  - orgId: 1
    name: 'obiente-system-health'
    folder: 'Obiente Cloud'
    interval: '1m'
    rules:
      # API Health Check
      - uid: 'api-health-check'
        title: 'API Health Check Failed'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'up{job="api"} == 0'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'Alerting'
        execErrState: 'Alerting'
        for: '2m'
        annotations:
          summary: 'API health check is failing'
          description: 'The API service has been down for more than 2 minutes'
        labels:
          severity: 'critical'
          service: 'api'

      # Metrics Collection Failures
      - uid: 'metrics-collection-failure'
        title: 'Metrics Collection Failure'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'obiente_metrics_collection_failures_total > 0'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '5m'
        annotations:
          summary: 'Metrics collection is failing'
          description: 'Metrics collection has failed {{ $value }} times'
        labels:
          severity: 'warning'
          service: 'metrics-collector'

      # Circuit Breaker Open
      - uid: 'circuit-breaker-open'
        title: 'Circuit Breaker is Open'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'obiente_circuit_breaker_state == 1'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '1m'
        annotations:
          summary: 'Circuit breaker is open'
          description: 'The circuit breaker has been opened, indicating repeated failures'
        labels:
          severity: 'critical'
          service: 'api'

      # Database Connection Pool Exhausted
      - uid: 'db-connection-pool-exhausted'
        title: 'Database Connection Pool Exhausted'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'obiente_db_pool_active_connections / obiente_db_pool_max_connections > 0.9'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '5m'
        annotations:
          summary: 'Database connection pool is nearly exhausted'
          description: 'Database connection pool usage is above 90%'
        labels:
          severity: 'warning'
          service: 'database'

      # High API Error Rate
      - uid: 'high-api-error-rate'
        title: 'High API Error Rate'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'rate(obiente_http_requests_total{status=~"5.."}[5m]) / rate(obiente_http_requests_total[5m]) > 0.05'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '5m'
        annotations:
          summary: 'API error rate is high'
          description: 'More than 5% of API requests are returning 5xx errors'
        labels:
          severity: 'warning'
          service: 'api'

      # Retry Queue Size
      - uid: 'retry-queue-size'
        title: 'Retry Queue Size is High'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'obiente_retry_queue_size > 100'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '10m'
        annotations:
          summary: 'Retry queue size is high'
          description: 'The retry queue has {{ $value }} items, indicating database write issues'
        labels:
          severity: 'warning'
          service: 'metrics-collector'

  - orgId: 1
    name: 'obiente-infrastructure'
    folder: 'Obiente Cloud'
    interval: '1m'
    rules:
      # Prometheus Target Down
      - uid: 'prometheus-target-down'
        title: 'Prometheus Target is Down'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'up == 0'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '5m'
        annotations:
          summary: 'Prometheus target is down'
          description: 'Target {{ $labels.instance }} (job: {{ $labels.job }}) is down'
        labels:
          severity: 'warning'
          service: 'monitoring'

      # High Memory Usage
      - uid: 'high-memory-usage'
        title: 'High Memory Usage'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '5m'
        annotations:
          summary: 'Container memory usage is high'
          description: 'Container {{ $labels.name }} is using more than 90% of its memory limit'
        labels:
          severity: 'warning'
          service: 'infrastructure'

      # High CPU Usage
      - uid: 'high-cpu-usage'
        title: 'High CPU Usage'
        condition: 'C'
        data:
          - refId: 'A'
            datasourceUid: 'prometheus'
            model:
              expr: 'rate(container_cpu_usage_seconds_total[5m]) > 0.9'
              intervalMs: 15000
              maxDataPoints: 43200
              format: 'time_series'
        noDataState: 'NoData'
        execErrState: 'Alerting'
        for: '10m'
        annotations:
          summary: 'Container CPU usage is high'
          description: 'Container {{ $labels.name }} is using more than 90% CPU'
        labels:
          severity: 'warning'
          service: 'infrastructure'

# Mute Timings - Define when alerts should be muted
muteTimings:
  - orgId: 1
    name: 'maintenance-window'
    time_intervals:
      - times:
          - start_time: '02:00'
            end_time: '04:00'
        weekdays: ['saturday', 'sunday']
        months: ['*']
        years: ['*']

