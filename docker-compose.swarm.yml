# Obiente Cloud - Docker Swarm Deployment
# This is a simplified setup. For high availability, use docker-compose.swarm.ha.yml

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-obiente-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-obiente-postgres}
      POSTGRES_DB: ${POSTGRES_DB:-obiente}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-obiente-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
    networks:
      - obiente-network

  timescaledb:
    image: timescale/timescaledb:latest-pg16
    environment:
      POSTGRES_USER: ${METRICS_DB_USER:-${POSTGRES_USER:-obiente-postgres}}
      POSTGRES_PASSWORD: ${METRICS_DB_PASSWORD:-${POSTGRES_PASSWORD:-obiente-postgres}}
      POSTGRES_DB: ${METRICS_DB_NAME:-obiente_metrics}
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${METRICS_DB_USER:-${POSTGRES_USER:-obiente-postgres}}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
    networks:
      - obiente-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 128M
    networks:
      - obiente-network

  api:
    image: ${API_IMAGE:-ghcr.io/obiente/cloud-api:latest}
    # Build section removed - using image from GitHub Container Registry
    # To build locally, set API_IMAGE=obiente/cloud-api:latest and uncomment build section below
    # build:
    #   context: .
    #   dockerfile: apps/api/Dockerfile
    environment:
      PORT: ${GO_API_PORT:-3001}
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: ${POSTGRES_USER:-obiente-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-obiente-postgres}
      DB_NAME: ${POSTGRES_DB:-obiente}
      METRICS_DB_HOST: timescaledb
      METRICS_DB_PORT: 5432
      METRICS_DB_USER: ${METRICS_DB_USER:-${POSTGRES_USER:-obiente-postgres}}
      METRICS_DB_PASSWORD: ${METRICS_DB_PASSWORD:-${POSTGRES_PASSWORD:-obiente-postgres}}
      METRICS_DB_NAME: ${METRICS_DB_NAME:-obiente_metrics}
      METRICS_COLLECTION_INTERVAL: ${METRICS_COLLECTION_INTERVAL:-5s}
      METRICS_STORAGE_INTERVAL: ${METRICS_STORAGE_INTERVAL:-60s}
      METRICS_LIVE_RETENTION: ${METRICS_LIVE_RETENTION:-5m}
      METRICS_MAX_WORKERS: ${METRICS_MAX_WORKERS:-50}
      METRICS_BATCH_SIZE: ${METRICS_BATCH_SIZE:-100}
      METRICS_MAX_LIVE_PER_DEPLOYMENT: ${METRICS_MAX_LIVE_PER_DEPLOYMENT:-1000}
      METRICS_MAX_PREVIOUS_STATS: ${METRICS_MAX_PREVIOUS_STATS:-10000}
      METRICS_DOCKER_API_TIMEOUT: ${METRICS_DOCKER_API_TIMEOUT:-10s}
      METRICS_DOCKER_API_RETRY_MAX: ${METRICS_DOCKER_API_RETRY_MAX:-3}
      METRICS_DOCKER_API_RETRY_BACKOFF_INITIAL: ${METRICS_DOCKER_API_RETRY_BACKOFF_INITIAL:-1s}
      METRICS_DOCKER_API_RETRY_BACKOFF_MAX: ${METRICS_DOCKER_API_RETRY_BACKOFF_MAX:-30s}
      METRICS_CIRCUIT_BREAKER_FAILURE_THRESHOLD: ${METRICS_CIRCUIT_BREAKER_FAILURE_THRESHOLD:-5}
      METRICS_CIRCUIT_BREAKER_COOLDOWN: ${METRICS_CIRCUIT_BREAKER_COOLDOWN:-1m}
      METRICS_CIRCUIT_BREAKER_HALFOPEN_MAX: ${METRICS_CIRCUIT_BREAKER_HALFOPEN_MAX:-3}
      METRICS_HEALTH_CHECK_INTERVAL: ${METRICS_HEALTH_CHECK_INTERVAL:-30s}
      METRICS_HEALTH_CHECK_FAILURE_THRESHOLD: ${METRICS_HEALTH_CHECK_FAILURE_THRESHOLD:-3}
      METRICS_SUBSCRIBER_BUFFER_SIZE: ${METRICS_SUBSCRIBER_BUFFER_SIZE:-100}
      METRICS_SUBSCRIBER_SLOW_THRESHOLD: ${METRICS_SUBSCRIBER_SLOW_THRESHOLD:-5s}
      METRICS_SUBSCRIBER_CLEANUP_INTERVAL: ${METRICS_SUBSCRIBER_CLEANUP_INTERVAL:-1m}
      METRICS_RETRY_MAX_RETRIES: ${METRICS_RETRY_MAX_RETRIES:-5}
      METRICS_RETRY_INTERVAL: ${METRICS_RETRY_INTERVAL:-1m}
      METRICS_RETRY_MAX_QUEUE_SIZE: ${METRICS_RETRY_MAX_QUEUE_SIZE:-10000}
      REDIS_URL: redis://redis:6379
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-debug}
      # CORS Configuration
      CORS_ORIGIN: ${CORS_ORIGIN:-*}
      # Authentication - Zitadel
      ZITADEL_URL: ${ZITADEL_URL:-https://auth.obiente.cloud}
      ZITADEL_MANAGEMENT_TOKEN: ${ZITADEL_MANAGEMENT_TOKEN:-}
      DISABLE_AUTH: ${DISABLE_AUTH:-false}
      SKIP_TLS_VERIFY: ${SKIP_TLS_VERIFY:-false}
      SUPERADMIN_EMAILS: ${SUPERADMIN_EMAILS:-}
      # DNS Configuration
      TRAEFIK_IPS: ${TRAEFIK_IPS:-} # Format: "region1:ip1,ip2;region2:ip3,ip4" or simple "ip1,ip2"
      DNS_IPS: ${DNS_IPS:-} # Comma-separated list of DNS server IPs
      DNS_PORT: ${DNS_PORT:-53} # DNS server port (default: 53)
      DB_LOG_LEVEL: ${DB_LOG_LEVEL:-}
      # Orchestration settings
      DEPLOYMENT_STRATEGY: ${DEPLOYMENT_STRATEGY:-least-loaded}
      MAX_DEPLOYMENTS_PER_NODE: ${MAX_DEPLOYMENTS_PER_NODE:-50}
      # Pricing Configuration (optional - defaults are used if not set)
      PRICING_CPU_COST_PER_CORE_SECOND: ${PRICING_CPU_COST_PER_CORE_SECOND:-0.000000761}
      PRICING_MEMORY_COST_PER_BYTE_SECOND: ${PRICING_MEMORY_COST_PER_BYTE_SECOND:-0.000000000000001063}
      PRICING_BANDWIDTH_COST_PER_BYTE: ${PRICING_BANDWIDTH_COST_PER_BYTE:-0.000000000009313}
      PRICING_STORAGE_COST_PER_BYTE_MONTH: ${PRICING_STORAGE_COST_PER_BYTE_MONTH:-0.000000000186264}
      # Stripe Payment Processing
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-}
      # Console/Dashboard URL for redirects (used by billing service)
      CONSOLE_URL: ${CONSOLE_URL:-${DASHBOARD_URL:-${APP_CONSOLE_URL:-https://app.obiente.cloud}}}
      DASHBOARD_URL: ${DASHBOARD_URL:-${CONSOLE_URL:-${APP_CONSOLE_URL:-https://app.obiente.cloud}}}
      APP_CONSOLE_URL: ${APP_CONSOLE_URL:-${CONSOLE_URL:-${DASHBOARD_URL:-https://app.obiente.cloud}}}
      # Support email (optional)
      SUPPORT_EMAIL: ${SUPPORT_EMAIL:-}
      # Swarm configuration - enable swarm features for swarm deployments
      ENABLE_SWARM: ${ENABLE_SWARM:-true} # Set to 'true' to enable Docker Swarm features (default: true for swarm)
    volumes:
      # Mount Docker socket to manage containers (read-write required)
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount Docker volumes directory for named volumes (read-only)
      - /var/lib/docker/volumes:/var/lib/docker/volumes:ro
      # Mount custom safe directories for sanitized bind mounts
      - /var/lib/obiente:/var/lib/obiente
      - /tmp/obiente-volumes:/tmp/obiente-volumes
      - /tmp/obiente-deployments:/tmp/obiente-deployments
    depends_on:
      - postgres
      - timescaledb
      - redis
    deploy:
      mode: global # One instance per node for local Docker access
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      resources:
        limits:
          cpus: "2"
          memory: 1G
        reservations:
          cpus: "1"
          memory: 512M
      labels:
        - "cloud.obiente.service=api"
        - "cloud.obiente.role=control-plane"
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        - "traefik.http.routers.api.rule=Host(`api.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.api.entrypoints=websecure"
        - "traefik.http.routers.api.tls.certresolver=letsencrypt"
        - "traefik.http.services.api.loadbalancer.server.port=3001"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget --no-verbose --tries=1 --spider http://localhost:${GO_API_PORT:-3001}/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - obiente-network

  traefik:
    image: traefik:v3.0
    command:
      - --api.dashboard=true
      - --api.insecure=true  # Enable API on port 8080 directly
      - --providers.swarm=true  # Use Swarm provider for Docker Swarm mode (v3.0)
      - --providers.swarm.exposedbydefault=false
      - --providers.swarm.network=obiente_obiente-network
      - --providers.swarm.watch=true  # Watch for service changes
      - --providers.swarm.constraints=Label(`cloud.obiente.traefik`,`true`)  # Only discover services with this label
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --entrypoints.deployments.address=:8000
      # Port 8080 is used by Traefik API (--api.insecure=true)
      # Grafana is accessible via port 80/443 at /grafana
      # Let's Encrypt
      - --certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL:-admin@example.com}
      - --certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json
      - --certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web
      # Metrics
      - --metrics.prometheus=true
      # Logging
      - --accesslog=true
      - --log.level=DEBUG  # Enable debug logging to see service discovery
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: ingress  # Ingress mode for Swarm load balancing
      - target: 443
        published: 443
        protocol: tcp
        mode: ingress  # Ingress mode for Swarm load balancing
      - target: 8000
        published: 8000
        protocol: tcp
        mode: ingress  # User deployments
      - target: 8080
        published: 8080
        protocol: tcp
        mode: ingress  # Traefik dashboard accessible on port 8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_letsencrypt:/letsencrypt
    deploy:
      mode: replicated  # Use replicated mode with ingress for proper Swarm load balancing
      replicas: 1
      update_config:
        parallelism: 1
        order: start-first
      placement:
        constraints:
          - node.labels.traefik.exclude != true  # Exclude nodes labeled with traefik.exclude=true
      resources:
        limits:
          cpus: "1"
          memory: 256M
        reservations:
          cpus: "0.5"
          memory: 128M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        # Traefik dashboard accessible directly on port 8080 via --api.insecure=true
        # Also route Traefik dashboard via HTTPS
        - "traefik.http.routers.traefik.rule=Host(`traefik.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.traefik.entrypoints=websecure"
        - "traefik.http.routers.traefik.tls.certresolver=letsencrypt"
        - "traefik.http.routers.traefik.service=api@internal"
    networks:
      - obiente-network

  dns:
    image: ${API_IMAGE:-ghcr.io/obiente/cloud-api:latest}
    # Build section removed - using image from GitHub Container Registry
    # To build locally, set API_IMAGE=obiente/cloud-api:latest and uncomment build section below
    # build:
    #   context: .
    #   dockerfile: apps/api/Dockerfile
    command: ["./dns-server"]
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: ${POSTGRES_USER:-obiente-postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-obiente-postgres}
      DB_NAME: ${POSTGRES_DB:-obiente}
      TRAEFIK_IPS: ${TRAEFIK_IPS:-} # Format: "region1:ip1,ip2;region2:ip3,ip4"
      DNS_IPS: ${DNS_IPS:-} # Comma-separated list of DNS server IPs
      DNS_PORT: ${DNS_PORT:-53} # DNS server port (default: 53)
    ports:
      - "${DNS_PORT:-53}:${DNS_PORT:-53}/udp"
      - "${DNS_PORT:-53}:${DNS_PORT:-53}/tcp"
    deploy:
      # Use placement constraints to control which nodes run DNS
      # By default, DNS runs on all nodes (global mode)
      # To delegate DNS to specific nodes:
      #   1. Set DNS_MODE=replicated in your .env file
      #   2. Set DNS_REPLICAS to the number of DNS instances you want
      #   3. Add node labels: docker node update --label-add dns.enabled=true <node-name>
      #   4. Uncomment/modify the constraint below to restrict DNS to specific nodes
      # Examples:
      #   - node.labels.dns.enabled == true (only runs on nodes with dns.enabled=true)
      #   - node.role == manager (only runs on manager nodes)
      #   - node.labels.dns.enabled != false (runs on all nodes except those with dns.enabled=false)
      # To disable DNS on specific nodes, label them: docker node update --label-add dns.enabled=false <node-name>
      mode: ${DNS_MODE:-global} # Options: global (all nodes), replicated (specific nodes)
      # replicas is only valid when mode is replicated
      # When using replicated mode, set DNS_REPLICAS environment variable
      # replicas: ${DNS_REPLICAS:-1} # Only used if mode is replicated
      # Placement constraints - uncomment to restrict DNS to specific nodes
      # placement:
      #   constraints:
      #     # Example: Run only on nodes with dns.enabled=true label
      #     # - node.labels.dns.enabled == true
      #     # Example: Run only on manager nodes
      #     # - node.role == manager
      #     # Example: Run on all nodes except those with dns.enabled=false
      #     # - node.labels.dns.enabled != false
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 128M
    # Note: DNS server needs CAP_NET_BIND_SERVICE capability to bind to port 53
    # In Docker Swarm, this requires privileged mode or specific capabilities
    cap_add:
      - NET_BIND_SERVICE
    healthcheck:
      test: ["CMD-SHELL", "nslookup -type=A deploy-test.my.obiente.cloud localhost || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - obiente-network

  # ============================================================================
  # MONITORING & OBSERVABILITY
  # ============================================================================

  # Prometheus - Metrics collection
  prometheus:
    image: prom/prometheus:latest
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
    volumes:
      - prometheus_data:/prometheus
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Required for Docker Swarm service discovery
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        - "traefik.http.routers.prometheus.rule=Host(`prometheus.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.prometheus.entrypoints=websecure"
        - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
        - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
    networks:
      - obiente-network

  # Grafana - Metrics visualization dashboard accessible at /grafana via Traefik
  grafana:
    image: grafana/grafana:latest
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_SERVER_ROOT_URL: https://grafana.${DOMAIN:-localhost}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards:ro
    depends_on:
      - prometheus
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 128M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        # Route Grafana at grafana.domain (Host-based routing)
        - "traefik.http.routers.grafana.rule=Host(`grafana.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.grafana.entrypoints=web"
        - "traefik.http.routers.grafana.service=grafana"
        - "traefik.http.services.grafana.loadbalancer.server.port=3000"
        # Route Grafana on HTTPS for production access
        - "traefik.http.routers.grafana-secure.rule=Host(`grafana.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.grafana-secure.entrypoints=websecure"
        - "traefik.http.routers.grafana-secure.tls.certresolver=letsencrypt"
        - "traefik.http.routers.grafana-secure.service=grafana"
    networks:
      - obiente-network

volumes:
  postgres_data:
    driver: local
  timescaledb_data:
    driver: local
  redis_data:
    driver: local
  traefik_letsencrypt:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local

networks:
  obiente-network:
    external: true
    name: obiente_obiente-network
    # Network must be created manually before deployment
    # Create with: docker network create --driver overlay --subnet <subnet> obiente_obiente-network
    # Or use: ./scripts/create-swarm-network.sh [--subnet <subnet>]
    # Default subnet if not specified: 10.0.9.0/24