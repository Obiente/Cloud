# Obiente Cloud - Docker Swarm Deployment
# This is a simplified setup. For high availability, use docker-compose.swarm.ha.yml

services:
  postgres:
    image: postgres:16-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-obiente_postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-obiente_postgres}
      POSTGRES_DB: ${POSTGRES_DB:-obiente}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-obiente_postgres} -d ${POSTGRES_DB:-obiente}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
    networks:
      - obiente-network

  timescaledb:
    image: timescale/timescaledb:latest-pg16
    environment:
      POSTGRES_USER: ${METRICS_DB_USER:-obiente_postgres}
      POSTGRES_PASSWORD: ${METRICS_DB_PASSWORD:-obiente_postgres}
      POSTGRES_DB: ${METRICS_DB_NAME:-obiente_metrics}
    volumes:
      - timescaledb_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${METRICS_DB_USER:-obiente_postgres} -d ${METRICS_DB_NAME:-obiente_metrics}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 1G
    networks:
      - obiente-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
      start_period: 10s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 128M
    networks:
      - obiente-network

  api:
    image: ${API_IMAGE:-ghcr.io/obiente/cloud-api:latest}
    # Build section removed - using image from GitHub Container Registry
    # To build locally, set API_IMAGE=obiente/cloud-api:latest and uncomment build section below
    # build:
    #   context: .
    #   dockerfile: apps/api/Dockerfile
    environment:
      PORT: ${GO_API_PORT:-3001}
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: ${POSTGRES_USER:-obiente_postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-obiente_postgres}
      DB_NAME: ${POSTGRES_DB:-obiente}
      METRICS_DB_HOST: timescaledb
      METRICS_DB_PORT: 5432
      METRICS_DB_USER: ${METRICS_DB_USER:-obiente_postgres}
      METRICS_DB_PASSWORD: ${METRICS_DB_PASSWORD:-obiente_postgres}
      METRICS_DB_NAME: ${METRICS_DB_NAME:-obiente_metrics}
      METRICS_COLLECTION_INTERVAL: ${METRICS_COLLECTION_INTERVAL:-5s}
      METRICS_STORAGE_INTERVAL: ${METRICS_STORAGE_INTERVAL:-60s}
      METRICS_LIVE_RETENTION: ${METRICS_LIVE_RETENTION:-5m}
      METRICS_MAX_WORKERS: ${METRICS_MAX_WORKERS:-50}
      METRICS_BATCH_SIZE: ${METRICS_BATCH_SIZE:-100}
      METRICS_MAX_LIVE_PER_DEPLOYMENT: ${METRICS_MAX_LIVE_PER_DEPLOYMENT:-1000}
      METRICS_MAX_PREVIOUS_STATS: ${METRICS_MAX_PREVIOUS_STATS:-10000}
      METRICS_DOCKER_API_TIMEOUT: ${METRICS_DOCKER_API_TIMEOUT:-10s}
      METRICS_DOCKER_API_RETRY_MAX: ${METRICS_DOCKER_API_RETRY_MAX:-3}
      METRICS_DOCKER_API_RETRY_BACKOFF_INITIAL: ${METRICS_DOCKER_API_RETRY_BACKOFF_INITIAL:-1s}
      METRICS_DOCKER_API_RETRY_BACKOFF_MAX: ${METRICS_DOCKER_API_RETRY_BACKOFF_MAX:-30s}
      METRICS_CIRCUIT_BREAKER_FAILURE_THRESHOLD: ${METRICS_CIRCUIT_BREAKER_FAILURE_THRESHOLD:-5}
      METRICS_CIRCUIT_BREAKER_COOLDOWN: ${METRICS_CIRCUIT_BREAKER_COOLDOWN:-1m}
      METRICS_CIRCUIT_BREAKER_HALFOPEN_MAX: ${METRICS_CIRCUIT_BREAKER_HALFOPEN_MAX:-3}
      METRICS_HEALTH_CHECK_INTERVAL: ${METRICS_HEALTH_CHECK_INTERVAL:-30s}
      METRICS_HEALTH_CHECK_FAILURE_THRESHOLD: ${METRICS_HEALTH_CHECK_FAILURE_THRESHOLD:-3}
      METRICS_SUBSCRIBER_BUFFER_SIZE: ${METRICS_SUBSCRIBER_BUFFER_SIZE:-100}
      METRICS_SUBSCRIBER_SLOW_THRESHOLD: ${METRICS_SUBSCRIBER_SLOW_THRESHOLD:-5s}
      METRICS_SUBSCRIBER_CLEANUP_INTERVAL: ${METRICS_SUBSCRIBER_CLEANUP_INTERVAL:-1m}
      METRICS_RETRY_MAX_RETRIES: ${METRICS_RETRY_MAX_RETRIES:-5}
      METRICS_RETRY_INTERVAL: ${METRICS_RETRY_INTERVAL:-1m}
      METRICS_RETRY_MAX_QUEUE_SIZE: ${METRICS_RETRY_MAX_QUEUE_SIZE:-10000}
      REDIS_URL: redis://redis:6379
      # Logging
      LOG_LEVEL: ${LOG_LEVEL:-debug}
      # CORS Configuration
      CORS_ORIGIN: ${CORS_ORIGIN:-*}
      # Authentication - Zitadel
      ZITADEL_URL: ${ZITADEL_URL:-https://auth.obiente.cloud}
      ZITADEL_CLIENT_ID: ${ZITADEL_CLIENT_ID:-}
      ZITADEL_MANAGEMENT_TOKEN: ${ZITADEL_MANAGEMENT_TOKEN:-}
      ZITADEL_ORGANIZATION_ID: ${ZITADEL_ORGANIZATION_ID:-}
      DISABLE_AUTH: ${DISABLE_AUTH:-false}
      SKIP_TLS_VERIFY: ${SKIP_TLS_VERIFY:-false}
      SUPERADMIN_EMAILS: ${SUPERADMIN_EMAILS:-}
      BILLING_ENABLED: ${BILLING_ENABLED:-true}
      SELF_HOSTED: ${SELF_HOSTED:-false}
      # DNS Configuration
      TRAEFIK_IPS: ${TRAEFIK_IPS:-} # Format: "region1:ip1,ip2;region2:ip3,ip4" or simple "ip1,ip2"
      DNS_IPS: ${DNS_IPS:-} # Comma-separated list of DNS server IPs
      DNS_PORT: ${DNS_PORT:-53} # DNS server port (default: 53)
        # VPS Configuration
      VPS_REGIONS: ${VPS_REGIONS:-} # Format: "region1:Name 1;region2:Name 2" or simple "region1"
      PROXMOX_API_URL: ${PROXMOX_API_URL:-}
      PROXMOX_USERNAME: ${PROXMOX_USERNAME:-root@pam}
      PROXMOX_PASSWORD: ${PROXMOX_PASSWORD:-}
      PROXMOX_TOKEN_ID: ${PROXMOX_TOKEN_ID:-}
      PROXMOX_TOKEN_SECRET: ${PROXMOX_TOKEN_SECRET:-}
      PROXMOX_STORAGE_POOL: ${PROXMOX_STORAGE_POOL:-local-lvm}
      PROXMOX_VM_ID_START: ${PROXMOX_VM_ID_START:-} # Starting VM ID range (e.g., 300)
      PROXMOX_VLAN_ID: ${PROXMOX_VLAN_ID:-} # Optional VLAN tag for VM network isolation (e.g., 100)
      SSH_PROXY_PORT: ${SSH_PROXY_PORT:-2222}
      # VPS Gateway Configuration (optional, for DHCP and SSH proxying)
      VPS_GATEWAY_URL: ${VPS_GATEWAY_URL:-} # gRPC URL for vps-gateway service (e.g., http://vps-gateway:8080)
      VPS_GATEWAY_API_SECRET: ${VPS_GATEWAY_API_SECRET:-} # Shared secret for authenticating with vps-gateway
      VPS_GATEWAY_BRIDGE: ${VPS_GATEWAY_BRIDGE:-vmbr1} # Bridge name for gateway network (defaults to vmbr1)
      # DNS Delegation Configuration (for self-hosted instances to push DNS records to production)
      # Set DNS_DELEGATION_PRODUCTION_API_URL to production API URL (e.g., "https://api.obiente.cloud")
      # Set DNS_DELEGATION_API_KEY to the API key received from production (see docs/deployment/dns-delegation.md)
      # Set DNS_DELEGATION_PUSH_INTERVAL to how often to push records (default: 2m)
      # Set DNS_DELEGATION_TTL to TTL for pushed records (default: 300s)
      DNS_DELEGATION_PRODUCTION_API_URL: ${DNS_DELEGATION_PRODUCTION_API_URL:-} # URL of production API
      DNS_DELEGATION_API_KEY: ${DNS_DELEGATION_API_KEY:-} # API key from production (required for pushing DNS records)
      DNS_DELEGATION_PUSH_INTERVAL: ${DNS_DELEGATION_PUSH_INTERVAL:-2m} # How often to push DNS records
      DNS_DELEGATION_TTL: ${DNS_DELEGATION_TTL:-300s} # TTL for pushed DNS records
      DB_LOG_LEVEL: ${DB_LOG_LEVEL:-}
      # Orchestration settings
      DEPLOYMENT_STRATEGY: ${DEPLOYMENT_STRATEGY:-least-loaded}
      MAX_DEPLOYMENTS_PER_NODE: ${MAX_DEPLOYMENTS_PER_NODE:-50}
      # Pricing Configuration (optional - defaults are used if not set)
      PRICING_CPU_COST_PER_CORE_SECOND: ${PRICING_CPU_COST_PER_CORE_SECOND:-0.000000761}
      PRICING_MEMORY_COST_PER_BYTE_SECOND: ${PRICING_MEMORY_COST_PER_BYTE_SECOND:-0.000000000000001063}
      PRICING_BANDWIDTH_COST_PER_BYTE: ${PRICING_BANDWIDTH_COST_PER_BYTE:-0.000000000009313}
      PRICING_STORAGE_COST_PER_BYTE_MONTH: ${PRICING_STORAGE_COST_PER_BYTE_MONTH:-0.000000000186264}
      # Stripe Payment Processing
      STRIPE_SECRET_KEY: ${STRIPE_SECRET_KEY:-}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_WEBHOOK_SECRET:-}
      # Dashboard URL for redirects (used by billing service and email notifications)
      DASHBOARD_URL: ${DASHBOARD_URL:-https://obiente.cloud}
      # Support email (optional)
      SUPPORT_EMAIL: ${SUPPORT_EMAIL:-}
      # SMTP configuration for email delivery
      SMTP_HOST: ${SMTP_HOST:-}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USERNAME: ${SMTP_USERNAME:-}
      SMTP_PASSWORD: ${SMTP_PASSWORD:-}
      SMTP_FROM_ADDRESS: ${SMTP_FROM_ADDRESS:-}
      SMTP_FROM_NAME: ${SMTP_FROM_NAME:-Obiente Cloud}
      SMTP_REPLY_TO: ${SMTP_REPLY_TO:-}
      SMTP_USE_STARTTLS: ${SMTP_USE_STARTTLS:-true}
      SMTP_SKIP_TLS_VERIFY: ${SMTP_SKIP_TLS_VERIFY:-false}
      SMTP_TIMEOUT_SECONDS: ${SMTP_TIMEOUT_SECONDS:-10}
      SMTP_LOCAL_NAME: ${SMTP_LOCAL_NAME:-api.obiente.local}
      # Swarm configuration - enable swarm features for swarm deployments
      ENABLE_SWARM: ${ENABLE_SWARM:-true} # Set to 'true' to enable Docker Swarm features (default: true for swarm)
      REGISTRY_USERNAME: ${REGISTRY_USERNAME:-obiente}
      REGISTRY_PASSWORD: ${REGISTRY_PASSWORD:-}
    volumes:
      # Mount Docker socket to manage containers (read-write required)
      - /var/run/docker.sock:/var/run/docker.sock
      # Mount Docker volumes directory for named volumes (read-only)
      - /var/lib/docker/volumes:/var/lib/docker/volumes:ro
      # Mount custom safe directories for sanitized bind mounts
      - /var/lib/obiente:/var/lib/obiente
      - /var/obiente/tmp/obiente-volumes:/tmp/obiente-volumes
      - /var/obiente/tmp/obiente-deployments:/tmp/obiente-deployments
    depends_on:
      - postgres
      - timescaledb
      - redis
    deploy:
      mode: global # One instance per node for local Docker access
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
        failure_action: rollback
        monitor: 60s
      rollback_config:
        parallelism: 1
        delay: 10s
        order: start-first
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      ports:
        - target: 2222
          published: ${SSH_PROXY_PORT:-2222}
          protocol: tcp
          mode: ingress  # SSH proxy port (exposed directly, bypassing Traefik)
      resources:
        limits:
          cpus: "2"
          memory: 1G
        reservations:
          cpus: "1"
          memory: 512M
      labels:
        - "cloud.obiente.service=api"
        - "cloud.obiente.role=control-plane"
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        - "traefik.http.routers.api.rule=Host(`api.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.api.entrypoints=web"
        - "traefik.http.routers.api.service=api"
        - "traefik.http.routers.api-secure.rule=Host(`api.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.api-secure.entrypoints=websecure"
        - "traefik.http.routers.api-secure.tls.certresolver=letsencrypt"
        - "traefik.http.routers.api-secure.service=api"
        # Service configuration
        - "traefik.http.services.api.loadbalancer.server.port=3001"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "curl -f http://localhost:${GO_API_PORT:-3001}/health || exit 1",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - obiente-network

  traefik:
    image: traefik:v3.0
    command:
      - --api.dashboard=true
      - --api.insecure=true  # Enable API on port 8080 directly
      - --providers.swarm=true  # Use Swarm provider for Docker Swarm mode (v3.0)
      - --providers.swarm.exposedbydefault=false
      - --providers.swarm.network=obiente_obiente-network
      - --providers.swarm.watch=true  # Watch for service changes
      - --providers.swarm.constraints=Label(`cloud.obiente.traefik`,`true`)  # Only discover services with this label
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --entrypoints.deployments.address=:8000
      # Port 8080 is used by Traefik API (--api.insecure=true)
      # Grafana is accessible via port 80/443 at /grafana
      # Let's Encrypt
      - --certificatesresolvers.letsencrypt.acme.email=${ACME_EMAIL:-admin@example.com}
      - --certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json
      - --certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web
      # Metrics
      - --metrics.prometheus=true
      # Logging
      - --accesslog=true
      - --log.level=DEBUG  # Enable debug logging to see service discovery
    ports:
      - target: 80
        published: 80
        protocol: tcp
        mode: ingress  # Ingress mode for Swarm load balancing
      - target: 443
        published: 443
        protocol: tcp
        mode: ingress  # Ingress mode for Swarm load balancing
      - target: 8000
        published: 8000
        protocol: tcp
        mode: ingress  # User deployments
      - target: 8080
        published: 8080
        protocol: tcp
        mode: ingress  # Traefik dashboard accessible on port 8080
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik_letsencrypt:/letsencrypt
    deploy:
      mode: replicated  # Use replicated mode with ingress for proper Swarm load balancing
      replicas: 1
      update_config:
        parallelism: 1
        order: start-first
      placement:
        constraints:
          - node.labels.traefik.exclude != true  # Exclude nodes labeled with traefik.exclude=true
      resources:
        limits:
          cpus: "1"
          memory: 256M
        reservations:
          cpus: "0.5"
          memory: 128M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        # Traefik dashboard accessible directly on port 8080 via --api.insecure=true
        # Also route Traefik dashboard via HTTPS
        - "traefik.http.routers.traefik.rule=Host(`traefik.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.traefik.entrypoints=websecure"
        - "traefik.http.routers.traefik.tls.certresolver=letsencrypt"
        - "traefik.http.routers.traefik.service=api@internal"
    networks:
      - obiente-network

  dns:
    image: ${API_IMAGE:-ghcr.io/obiente/cloud-api:latest}
    # Build section removed - using image from GitHub Container Registry
    # To build locally, set API_IMAGE=obiente/cloud-api:latest and uncomment build section below
    # build:
    #   context: .
    #   dockerfile: apps/api/Dockerfile
    command: ["./dns-server"]
    environment:
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: ${POSTGRES_USER:-obiente_postgres}
      DB_PASSWORD: ${POSTGRES_PASSWORD:-obiente_postgres}
      DB_NAME: ${POSTGRES_DB:-obiente}
      TRAEFIK_IPS: ${TRAEFIK_IPS:-} # Format: "region1:ip1,ip2;region2:ip3,ip4"
      DNS_IPS: ${DNS_IPS:-} # Comma-separated list of DNS server IPs
      DNS_PORT: ${DNS_PORT:-53} # DNS server port (default: 53)
    ports:
      # Use host mode publishing to expose port 53 directly on the host
      # DNS only runs on nodes labeled with dns.enabled=true, so only those nodes will bind to port 53
      # Other nodes will not run DNS at all (no binding attempt)
      # Note: Long form doesn't support env vars, so we use hardcoded 53 (DNS_PORT env var is for internal use)
      - target: 53
        published: 53
        protocol: udp
        mode: host
      - target: 53
        published: 53
        protocol: tcp
        mode: host
    deploy:
      # DNS runs ONLY on nodes labeled with dns.enabled=true
      # This prevents other nodes from even attempting to bind to port 53
      # To configure:
      #   1. Label the DNS IP node(s): docker node update --label-add dns.enabled=true <node-name>
      #   2. Set DNS_REPLICAS to the number of DNS instances (default: 1)
      #   3. DNS will only run on nodes with dns.enabled=true label
      mode: replicated # Must be replicated to use placement constraints
      replicas: ${DNS_REPLICAS:-1} # Number of DNS instances (typically 1 for single DNS IP node)
      placement:
        constraints:
          # Only run DNS on nodes explicitly labeled with dns.enabled=true
          - node.labels.dns.enabled == true
      update_config:
        parallelism: 1
        delay: 10s
        order: start-first
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 128M
    # Note: DNS server needs CAP_NET_BIND_SERVICE capability to bind to port 53
    # In Docker Swarm, this requires privileged mode or specific capabilities
    cap_add:
      - NET_BIND_SERVICE
    healthcheck:
      test: ["CMD-SHELL", "if command -v nc >/dev/null 2>&1; then nc -z localhost 53 || exit 1; else (apk add --no-cache netcat-openbsd >/dev/null 2>&1 || apt-get update -qq && apt-get install -y -qq netcat-openbsd >/dev/null 2>&1 || yum install -y -q nc >/dev/null 2>&1) && nc -z localhost 53 || exit 1; fi"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - obiente-network

  # ============================================================================
  # MONITORING & OBSERVABILITY
  # ============================================================================

  # Prometheus - Metrics collection
  prometheus:
    image: prom/prometheus:latest
    user: "0:0"  # Run as root to access Docker socket for Swarm service discovery
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=15d"
    volumes:
      - prometheus_data:/prometheus
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro  # Required for Docker Swarm service discovery
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 512M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        - "traefik.http.routers.prometheus.rule=Host(`prometheus.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.prometheus.entrypoints=websecure"
        - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
        - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
    networks:
      - obiente-network

  # Grafana - Metrics visualization dashboard accessible at /grafana via Traefik
  grafana:
    image: grafana/grafana:latest
    user: "0:0"  # Run as root for entrypoint script to write provisioning files
    entrypoint: ["/bin/sh", "/etc/grafana/entrypoint.sh"]
    command: ["/run.sh"]
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_SERVER_ROOT_URL: https://grafana.${DOMAIN:-localhost}
      # Disable strict provisioning validation to avoid conflicts
      GF_PROVISIONING_DATASOURCES_ALLOW_DELETION: "true"
      # Allow unsigned plugins (for lokiexplore-app and other community plugins)
      GF_PLUGINS_ALLOW_LOADING_UNSIGNED_PLUGINS: "grafana-lokiexplore-app"
      # Pass database credentials as environment variables for datasource provisioning
      POSTGRES_USER: ${POSTGRES_USER:-obiente_postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-obiente_postgres}
      METRICS_DB_USER: ${METRICS_DB_USER:-obiente_postgres}
      METRICS_DB_PASSWORD: ${METRICS_DB_PASSWORD:-obiente_postgres}
      # Datasource host configuration (for regular swarm, use direct service names)
      GRAFANA_POSTGRES_HOST: ${GRAFANA_POSTGRES_HOST:-postgres}
      GRAFANA_METRICS_DB_HOST: ${GRAFANA_METRICS_DB_HOST:-timescaledb}
      # Alerting configuration
      ALERT_EMAIL: ${ALERT_EMAIL:-admin@example.com}
      # SMTP configuration for Grafana email notifications (only set if SMTP_HOST is configured)
      # These will be conditionally set by the entrypoint script
      SMTP_HOST: ${SMTP_HOST:-}
      SMTP_PORT: ${SMTP_PORT:-587}
      SMTP_USERNAME: ${SMTP_USERNAME:-}
      SMTP_PASSWORD: ${SMTP_PASSWORD:-}
      SMTP_FROM_ADDRESS: ${SMTP_FROM_ADDRESS:-}
      SMTP_FROM_NAME: ${SMTP_FROM_NAME:-Grafana}
      SMTP_SKIP_TLS_VERIFY: ${SMTP_SKIP_TLS_VERIFY:-false}
      SMTP_USE_STARTTLS: ${SMTP_USE_STARTTLS:-true}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:rw
      - ./monitoring/grafana/dashboards:/etc/grafana/dashboards:ro
      - ./monitoring/grafana/entrypoint.sh:/etc/grafana/entrypoint.sh:ro
    depends_on:
      - prometheus
      - postgres
      - timescaledb
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.5"
          memory: 256M
        reservations:
          cpus: "0.25"
          memory: 128M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        # Route Grafana at grafana.domain (Host-based routing)
        - "traefik.http.routers.grafana.rule=Host(`grafana.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.grafana.entrypoints=web"
        - "traefik.http.routers.grafana.service=grafana"
        - "traefik.http.services.grafana.loadbalancer.server.port=3000"
        # Route Grafana on HTTPS for production access
        - "traefik.http.routers.grafana-secure.rule=Host(`grafana.${DOMAIN:-localhost}`)"
        - "traefik.http.routers.grafana-secure.entrypoints=websecure"
        - "traefik.http.routers.grafana-secure.tls.certresolver=letsencrypt"
        - "traefik.http.routers.grafana-secure.service=grafana"
    networks:
      - obiente-network

  # Docker Registry - Host images for Swarm deployments
  registry:
    image: registry:2
    environment:
      REGISTRY_STORAGE_FILESYSTEM_ROOTDIRECTORY: /var/lib/registry
      REGISTRY_HTTP_ADDR: 0.0.0.0:5000
      # Allow deletion of images (useful for cleanup)
      REGISTRY_STORAGE_DELETE_ENABLED: "true"
      # Enable basic auth for private repositories
      REGISTRY_AUTH: htpasswd
      REGISTRY_AUTH_HTPASSWD_PATH: /auth/htpasswd
      REGISTRY_AUTH_HTPASSWD_REALM: "Obiente Cloud Registry"
    volumes:
      - registry_data:/var/lib/registry
      # Use bind mount for auth directory to allow easy setup from host
      - /var/lib/obiente/registry-auth:/auth:ro
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'if command -v nc >/dev/null 2>&1; then nc -z localhost 5000 || exit 1; else (apk add --no-cache netcat-openbsd >/dev/null 2>&1 || apt-get update -qq && apt-get install -y -qq netcat-openbsd >/dev/null 2>&1 || yum install -y -q nc >/dev/null 2>&1) && nc -z localhost 5000 || exit 1; fi'"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "1"
          memory: 512M
        reservations:
          cpus: "0.25"
          memory: 256M
      labels:
        - "cloud.obiente.traefik=true"
        - "traefik.enable=true"
        - "traefik.http.routers.registry.rule=Host(`registry.${DOMAIN:-obiente.cloud}`)"
        - "traefik.http.routers.registry.entrypoints=websecure"
        - "traefik.http.routers.registry.tls.certresolver=letsencrypt"
        - "traefik.http.routers.registry.service=registry"
        - "traefik.http.services.registry.loadbalancer.server.port=5000"
    networks:
      - obiente-network

  # Note: vps-gateway service is deployed separately using docker-compose.vps-gateway.yml
  # It should be deployed on the gateway VM/container with network_mode: host

volumes:
  postgres_data:
    driver: local
  timescaledb_data:
    driver: local
  redis_data:
    driver: local
  traefik_letsencrypt:
    driver: local
  prometheus_data:
    driver: local
  grafana_data:
    driver: local
  registry_data:
    driver: local

networks:
  obiente-network:
    external: true
    name: obiente_obiente-network
    # Network must be created manually before deployment
    # Create with: docker network create --driver overlay --subnet <subnet> obiente_obiente-network
    # Or use: ./scripts/create-swarm-network.sh [--subnet <subnet>]
    # Default subnet if not specified: 10.0.9.0/24